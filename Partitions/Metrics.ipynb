{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee9664a",
   "metadata": {},
   "source": [
    "# **Non Extreme Distribution (NED)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af3917",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Non-Extreme Distribution Function\n",
    "\n",
    "This function calculates the **non-extreme distribution (NED)** metric for a software system based on\n",
    "its partitioning. The NED metric measures the proportion of classes assigned to partitions of\n",
    "extreme sizes (very small or very large), helping to identify imbalances in the partitioning.\n",
    "\n",
    "Parameters:\n",
    "- partition_class_bcs_assignment (dict): A dictionary where keys represent partitions, and values\n",
    "  are dictionaries containing the 'classes' assigned to each partition.\n",
    "  Example:\n",
    "  {\n",
    "      'partition_1': {'classes': ['ClassA', 'ClassB']},\n",
    "      'partition_2': {'classes': ['ClassC', 'ClassD']}\n",
    "  }\n",
    "- result (dict, optional): An intermediate result (defaults to None). This parameter allows flexibility\n",
    "  for pre-processed data or alternative representations of partition assignments.\n",
    "\n",
    "Returns:\n",
    "- float: The non-extreme distribution (NED) value, which ranges from 0 to 1. A value closer to 0\n",
    "  indicates extreme partitioning sizes, while a value closer to 1 represents balanced partitioning.\n",
    "\n",
    "Steps:\n",
    "1. Count the total number of classes and the number of classes in partitions of \"non-extreme\" size.\n",
    "2. Calculate the NED metric as the proportion of classes in extreme-sized partitions.\n",
    "3. Return the NED value rounded to three decimal places.\n",
    "\"\"\"\n",
    "\n",
    "def non_extreme_distribution(partition_class_bcs_assignment, result=None):\n",
    "    \"\"\"\n",
    "    Calculate the non-extreme distribution (NED) metric for a partitioning of classes.\n",
    "\n",
    "    Parameters:\n",
    "    - partition_class_bcs_assignment (dict): Partition assignment of classes.\n",
    "    - result (dict, optional): Intermediate result. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    - float: Non-extreme distribution value.\n",
    "    \"\"\"\n",
    "    # Step 1: Use the provided partition assignment or initialize `result` with the input\n",
    "    if result is None:\n",
    "        result = partition_class_bcs_assignment\n",
    "\n",
    "    # Extract the cluster (partition) names and count the number of clusters\n",
    "    clusters = list(result.keys())\n",
    "    n_clusters = len(clusters)  # Total number of partitions (clusters)\n",
    "\n",
    "    # Initialize variables for calculating the metric\n",
    "    sum_non_extreme = 0  # Accumulate the size of partitions in the non-extreme range\n",
    "    total_classes = 0    # Total number of classes across all partitions\n",
    "\n",
    "    # Step 2: Iterate through each partition\n",
    "    for cluster in clusters:\n",
    "        # Number of classes in the current partition\n",
    "        size = len(partition_class_bcs_assignment[cluster]['classes'])\n",
    "        total_classes += size  # Add to the total class count\n",
    "\n",
    "        # Check if the partition size is within the \"non-extreme\" range (5 <= size <= 20)\n",
    "        if 5 <= size <= 20:\n",
    "            sum_non_extreme += size  # Add to the non-extreme class count\n",
    "\n",
    "    # Step 3: Calculate the non-extreme distribution (NED) metric\n",
    "    # NED is initialized to 1 (ideal balance). Adjust based on partition sizes.\n",
    "    ned = 1\n",
    "    if total_classes > 0 and sum_non_extreme > 0:\n",
    "        # Subtract the proportion of classes in non-extreme partitions from 1\n",
    "        ned = ned - (sum_non_extreme / total_classes)\n",
    "\n",
    "    # Step 4: Return the NED value rounded to three decimal places\n",
    "    return round(ned, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9201d",
   "metadata": {},
   "source": [
    "# **Conceptual Modularity Quality (CMQ)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261cdb2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calculate_ccoh(partition_class_bcs_assignment, runtime_call_volume):\n",
    "    \"\"\"\n",
    "    Compute **cohesion** (ccohi) within each partition.\n",
    "\n",
    "    Cohesion measures the degree of relatedness among classes within a partition.\n",
    "    Higher cohesion indicates that classes within a partition are strongly related.\n",
    "\n",
    "    Parameters:\n",
    "    - partition_class_bcs_assignment (dict): Mapping of partitions to their assigned classes.\n",
    "      Example:\n",
    "      {\n",
    "          'PartitionA': {'classes': ['Class1', 'Class2']},\n",
    "          'PartitionB': {'classes': ['Class3']}\n",
    "      }\n",
    "    - runtime_call_volume (set): Set of runtime call relationships (not used in this function but\n",
    "      passed for consistency with other metrics).\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of cohesion (ccoh) values, one for each partition.\n",
    "      Example: [0.8, 0.9]\n",
    "    \"\"\"\n",
    "    ccoh = []  # Initialize the list to store cohesion values\n",
    "\n",
    "    # Iterate over each partition in the assignment\n",
    "    for partition in partition_class_bcs_assignment.values():\n",
    "        classes = partition['classes']  # Classes belonging to the current partition\n",
    "        Ni = len(classes)  # Total number of classes in the partition\n",
    "\n",
    "        # Count unique pairs of classes, excluding self-references\n",
    "        ui = sum(1 for c1 in classes for c2 in classes if c1 != c2)\n",
    "\n",
    "        # Calculate cohesion using the formula: ui / (Ni * (Ni - 1))\n",
    "        # Avoid division by zero when Ni <= 1\n",
    "        ccoh_i = ui / (Ni * (Ni - 1)) if Ni > 1 else 0\n",
    "\n",
    "        # Append the cohesion value for the current partition\n",
    "        ccoh.append(ccoh_i)\n",
    "\n",
    "    return ccoh\n",
    "\n",
    "def calculate_ccop(partition_class_bcs_assignment, runtime_call_volume):\n",
    "    \"\"\"\n",
    "    Compute **coupling** (ccopi;j) between partitions.\n",
    "\n",
    "    Coupling measures the degree of interaction between classes from different partitions.\n",
    "    Lower coupling indicates better modularity, as partitions are more independent.\n",
    "\n",
    "    Parameters:\n",
    "    - partition_class_bcs_assignment (dict): Mapping of partitions to their assigned classes.\n",
    "    - runtime_call_volume (set): Set of runtime call relationships.\n",
    "      Each item is a tuple representing a call trace (source, target).\n",
    "      Example: {('Class1', 'Class3'), ('Class2', 'Class4')}\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of coupling (ccop) values, one for each pair of partitions.\n",
    "      Example: [0.1, 0.2]\n",
    "    \"\"\"\n",
    "    ccop = []  # Initialize the list to store coupling values\n",
    "    partitions = list(partition_class_bcs_assignment.keys())  # List of partition names\n",
    "    M = len(partitions)  # Total number of partitions\n",
    "\n",
    "    # Iterate over all unique pairs of partitions (i, j)\n",
    "    for i in range(M):\n",
    "        for j in range(i + 1, M):\n",
    "            # Retrieve classes belonging to partitions i and j\n",
    "            classes_i = partition_class_bcs_assignment[partitions[i]]['classes']\n",
    "            classes_j = partition_class_bcs_assignment[partitions[j]]['classes']\n",
    "            Ni = len(classes_i)  # Number of classes in partition i\n",
    "            Nj = len(classes_j)  # Number of classes in partition j\n",
    "\n",
    "            # Count interactions (call traces) between classes in partitions i and j\n",
    "            sigma_ij = sum(1 for trace in runtime_call_volume\n",
    "                           if trace[0] in classes_i and trace[1] in classes_j)\n",
    "\n",
    "            # Calculate coupling using the formula: sigma_ij / (2 * Ni * Nj)\n",
    "            # Avoid division by zero when Ni * Nj <= 0\n",
    "            ccop_ij = sigma_ij / (2 * Ni * Nj) if Ni * Nj > 0 else 0\n",
    "\n",
    "            # Append the coupling value for the current partition pair\n",
    "            ccop.append(ccop_ij)\n",
    "\n",
    "    return ccop\n",
    "\n",
    "def calculate_cmq(partition_class_bcs_assignment, runtime_call_volume):\n",
    "    \"\"\"\n",
    "    Compute **Conceptual Modularity Quality** (CMQ).\n",
    "\n",
    "    CMQ combines cohesion (ccoh) and coupling (ccop) to provide a single metric for modularity.\n",
    "    Higher CMQ values indicate better modularity, with high cohesion and low coupling.\n",
    "\n",
    "    Parameters:\n",
    "    - partition_class_bcs_assignment (dict): Mapping of partitions to their assigned classes.\n",
    "    - runtime_call_volume (set): Set of runtime call relationships.\n",
    "\n",
    "    Returns:\n",
    "    - float: The CMQ value.\n",
    "      Example: 0.75\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate cohesion (ccoh) values for all partitions\n",
    "    ccoh_values = calculate_ccoh(partition_class_bcs_assignment, runtime_call_volume)\n",
    "\n",
    "    # Step 2: Calculate coupling (ccop) values for all partition pairs\n",
    "    ccop_values = calculate_ccop(partition_class_bcs_assignment, runtime_call_volume)\n",
    "\n",
    "    # Step 3: Compute the number of partitions\n",
    "    M = len(ccoh_values)\n",
    "\n",
    "    # Step 4: Calculate CMQ numerator (sum of cohesion values)\n",
    "    numerator = sum(ccoh_values)\n",
    "\n",
    "    # Step 5: Calculate the average coupling between partitions\n",
    "    denominator = M * (M - 1) / 2  # Total number of unique partition pairs\n",
    "    avg_ccop = sum(ccop_values) / denominator if denominator > 0 else 0  # Avoid division by zero\n",
    "\n",
    "    # Step 6: Compute the CMQ value using the formula: (sum(ccoh) / M) - avg(ccop)\n",
    "    CMQ = (numerator / M) - avg_ccop\n",
    "\n",
    "    return CMQ\n",
    "\n",
    "\n",
    "# Example usage of the CMQ function\n",
    "# Ensure partition assignments and runtime call volume data are provided\n",
    "# Example input data (user-defined based on system under analysis)\n",
    "# CMQ_value = calculate_cmq(partition_class_bcs_assignment, runtime_call_volume)\n",
    "# print(\"CMQ Value:\", CMQ_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7615b0",
   "metadata": {},
   "source": [
    "# **Precision/Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f165a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, List, Set, Tuple, Union\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Validation Approach\n",
    "# To ensure a fair and context-sensitive evaluation of decomposition quality, we employed a hybrid approach combining two complementary precision-recall metrics. The first metric, pairwise-based precision and recall, is particularly suited for overly fragmented decompositions, where the number of predicted partitions significantly exceeds the ground truth. This metric evaluates whether class pairs that should co-exist in the same service are preserved, making it ideal for assessing the cohesion of predictions in high-fragmentation scenarios. In contrast, the second metric, microservice-level precision and recall, is more appropriate when the predicted partitioning is closer in scale to the ground truth. It evaluates how well each predicted cluster aligns with the most similar ground truth cluster, capturing service-level cohesion and coupling. By dynamically selecting the metric based on the ratio of predicted to actual service count, we align the evaluation with the structure of each decomposition, avoiding bias toward either under- or over-fragmentation. \n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# Input Cluster Dictionaries\n",
    "# ---------------------------\n",
    "\n",
    "# Ground truth (flat format)\n",
    "flat_ground_truth_dict = {}\n",
    "\n",
    "# Predicted clusters (flat format)\n",
    "partition_class_assignment = {}\n",
    "\n",
    "# ---------------------------\n",
    "# Helper Functions\n",
    "# ---------------------------\n",
    "\n",
    "ClusterDict = Dict[str, Union[List[str], Dict[str, List[str]]]]\n",
    "\n",
    "def pairs_from_partitions(partitions: ClusterDict) -> Set[frozenset]:\n",
    "    if all(isinstance(v, dict) and \"classes\" in v for v in partitions.values()):\n",
    "        iter_lists = (v[\"classes\"] for v in partitions.values())\n",
    "    elif all(isinstance(v, list) for v in partitions.values()):\n",
    "        iter_lists = partitions.values()\n",
    "    else:\n",
    "        raise ValueError(\"Mixed or unsupported partition format detected.\")\n",
    "    pair_set = set()\n",
    "    for cls_list in iter_lists:\n",
    "        clean = [c for c in set(cls_list) if c]\n",
    "        for a, b in combinations(clean, 2):\n",
    "            pair_set.add(frozenset((a, b)))\n",
    "    return pair_set\n",
    "\n",
    "def flatten_clusters(d: ClusterDict) -> List[Set[str]]:\n",
    "    clusters: List[Set[str]] = []\n",
    "    for value in d.values():\n",
    "        if isinstance(value, list):\n",
    "            if value:\n",
    "                clusters.append(set(value))\n",
    "        elif isinstance(value, dict):\n",
    "            for classes in value.values():\n",
    "                if classes:\n",
    "                    clusters.append(set(classes))\n",
    "    return clusters\n",
    "\n",
    "def best_overlap(cluster: Set[str], gold_clusters: List[Set[str]]) -> Set[str]:\n",
    "    best, best_score = set(), -1.0\n",
    "    for gold in gold_clusters:\n",
    "        score = len(cluster & gold) / len(cluster) if cluster else 0\n",
    "        if score > best_score:\n",
    "            best, best_score = gold, score\n",
    "    return best\n",
    "\n",
    "def precision_recall_microservice(pred_clusters: List[Set[str]], gold_clusters: List[Set[str]]) -> Tuple[float, float]:\n",
    "    precisions, recalls = [], []\n",
    "    for pred in pred_clusters:\n",
    "        gold = best_overlap(pred, gold_clusters)\n",
    "        inter = len(pred & gold)\n",
    "        precisions.append(inter / len(pred) if pred else 0)\n",
    "        recalls.append(inter / len(gold) if gold else 0)\n",
    "    return (sum(precisions) / len(precisions),\n",
    "            sum(recalls) / len(recalls))\n",
    "\n",
    "# ---------------------------\n",
    "# Hybrid Evaluation Logic\n",
    "# ---------------------------\n",
    "\n",
    "num_predicted = len(partition_class_assignment)\n",
    "num_ground_truth = len(flat_ground_truth_dict)\n",
    "\n",
    "if num_predicted > 2 * num_ground_truth:\n",
    "    # Use Metric Formula 1 (Pairwise)\n",
    "    predicted_pairs = pairs_from_partitions(partition_class_assignment)\n",
    "    actual_pairs = pairs_from_partitions(flat_ground_truth_dict)\n",
    "    tp_pairs = predicted_pairs & actual_pairs\n",
    "    precision = len(tp_pairs) / len(predicted_pairs) if predicted_pairs else 0.0\n",
    "    recall = len(tp_pairs) / len(actual_pairs) if actual_pairs else 0.0\n",
    "    metric_used = \"Precision/Recall\"\n",
    "else:\n",
    "    # Use Metric Formula 2 (Microservice-level)\n",
    "    pred_clusters = flatten_clusters(partition_class_assignment)\n",
    "    gold_clusters = flatten_clusters(flat_ground_truth_dict)\n",
    "    precision, recall = precision_recall_microservice(pred_clusters, gold_clusters)\n",
    "    metric_used = \"Precision/Recall\"\n",
    "\n",
    "print(\"Hybrid Precision/Recall Evaluation\")\n",
    "print(\"----------------------------------\")\n",
    "print(f\"Metric Used              : {metric_used}\")\n",
    "print(f\"Precision                : {precision:.4f}\")\n",
    "print(f\"Recall                   : {recall:.4f}\")\n",
    "print(f\"# Predicted Partitions   : {num_predicted}\")\n",
    "print(f\"# Ground Truth Partitions: {num_ground_truth}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
